{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스태킹 앙상블 모델\n",
    "- 개별적인 기반 모델 + 최종 메타 모델\n",
    "- 최종 메타 모델 : 개별 기반 모델에서 얻은 예측 데이터를 훈련 데이터로 사용해 학습하는 모델\n",
    "- 여러 개별 모델의 예측 데이터를 각각 스태킹 형태로 결합해 최종 메타 모델의 학습용 피처 데이터 세트와 테스트용 피처 데이터 세트를 만드는 모델\n",
    "- 장점 : 높은 성능 / 단점 : 어마어마어마하게 느림\n",
    "- 실제 비즈니스보단 kaggle 같은 정확성만 요구되는 대회에서 많이 쓰임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 회귀\n",
    "- 종속변수가 연속변수인 데이터 예측\n",
    "- 스태킹 회귀 모델은 실제값과 예측값의 차이인 오류를 최소로 줄일 수 있는 선형 함수를 찾아 이를 접목하는 것\n",
    "- 따라서 스태킹 회귀 모델에서 최종 메타 모델은 선형회귀 모델이어야 합니다. (Ridge / Lasso / Linear) \n",
    "- 예) 집값 예측 / 주문량 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사전에 필요한 작업\n",
    "# 1. 파일 불러오기\n",
    "path = ''\n",
    "df = pd.read_csv(path, encoding='utf-8')\n",
    "\n",
    "# 2. 훈련용 데이터 / 테스트용 데이터 분리하기\n",
    "split = 10000\n",
    "target = ''\n",
    "\n",
    "### df 확보 후 target, 즉 예측해야할 칼럼값을 맨 앞자리에 두자.\n",
    "df.columns = [target, 'col1', 'col2', 'col3']\n",
    "result_df = df[target]\n",
    "reason_df = df.iloc[:, 1:]\n",
    "X_train = reason_df[:split]\n",
    "X_test = reason_df[split:]\n",
    "y_train = result_df[:split]\n",
    "y_test = result_df[split:]\n",
    "\n",
    "# 3. ridge, lasso, xgbr, lgbmr 모델 만들어두기\n",
    "# xgbr과 lgbmr은 best params을 찾기 위해 gridsearchCV 진행\n",
    "ridge_reg = Ridge(alpha=8)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "params = {\n",
    "    'num_leaves': [26, 27, 28, 29],\n",
    "    'learning_rate': [0.07, 0.05],\n",
    "    'max_depth': [-1, -2, -3],\n",
    "    'n_estimators': [1000, 2000, 3000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(LGBMRegressor(), params, scoring='neg_mean_squared_error', cv=3, n_jobs=multiprocessing.cpu_count())\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV 파라미터 : {}\".format(gs.best_params_))\n",
    "print(\"GridSearchCV 결과 : {}\".format(gs.best_score_))\n",
    "\n",
    "lgbm_reg = LGBMRegressor(learning_rate=gs.best_params_['learning_rate'], max_depth=gs.best_params_['max_depth'], n_estimators=gs.best_params_['n_estimators'], num_leaves=gs.best_params_['num_leaves'])\n",
    "lgbm_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "param = {\n",
    "    'max_depth':[2,3,4],\n",
    "    'n_estimators':range(300,600,100), #  'n_estimators':range(600,700,50) 여기에 cv 10 (이거와 별반차이가 없다.)\n",
    "    'colsample_bytree':[0.5,0.7,1],\n",
    "    'colsample_bylevel':[0.5,0.7,1]\n",
    "}\n",
    "model = XGBRegressor()\n",
    "gs = GridSearchCV(estimator=model, param_grid=param, cv=3, \n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           n_jobs=multiprocessing.cpu_count())\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"GridSearchCV 파라미터 : {}\".format(gs.best_params_))\n",
    "print(\"GridSearchCV 결과 : {}\".format(gs.best_score_))\n",
    "\n",
    "\n",
    "xgb_reg = XGBRegressor(n_estimators=gs.best_params_['n_estimators'], colsample_bylevel=gs.best_params_['colsample_bylevel'], learning_rate=0.1, colsample_bytree=gs.best_params_['colsample_bytree'], max_depth=gs.best_params_['max_depth'])\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    # 추후에 메타 모델이 사용할 학습 데이터 변환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros(X_test_n.shape[0], n_folds)\n",
    "    print(model.__class__.__name__, 'Model 시작')\n",
    "\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n",
    "        print('\\t 폴드세트 : ', folder_counter, '시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "\n",
    "        # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        # 입력된 원본 테스트 데이터를 폴드 세트 내 학습된 기반 모델에서 예측 후 데이터 저장\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "\n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "\n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_stacking_base_datasets()은  리턴값은 ndarray 배열을 인자로 사용하게끔 만들었음\n",
    "# DataFrame은 넘파이로 변환 후 사용\n",
    "X_train_n = X_train.values\n",
    "X_test_n = X_test.values\n",
    "y_train_n = y_train.values\n",
    "\n",
    "# 각 개별 기반(base) 모델이 생성한 학습용/테스트용 데이터 반환\n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "lasso_train, lasso_test = get_stacking_base_datasets(lasso_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgbr_train, xgbr_test = get_stacking_base_datasets(xgb_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "lgbmr_train, lgbmr_test = get_stacking_base_datasets(lgbm_reg, X_train_n, y_train_n, X_test_n, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델이 반환한 학습 및 테스트용 데이터 세트를 스태킹 형태로 결합\n",
    "stack_final_X_train = np.concatenate((ridge_train, lasso_train, xgbr_train, lgbmr_train), axis=1)\n",
    "stack_final_X_test = np.concatenate((ridge_test, lasso_test, xgbr_test, lgbmr_test), axis=1)\n",
    "\n",
    "# 최종 메타 모델은 라쏘 모델 적용\n",
    "meta_model_lasso = Lasso(alpha=0.0005)\n",
    "\n",
    "# 개별 모델 예측값을 기반으로 새롭게 만들어진 학습(테스트 데이터로 메타 모델 예측 및 RMSE 측정\n",
    "meta_model_lasso.fit(stack_final_X_train, y_train)\n",
    "final = meta_model_lasso.predict(stack_final_X_test)\n",
    "mse = metrics.mean_squared_error(y_test, final)\n",
    "rmse = np.sqrt(mse)\n",
    "print('스태킹 회귀 모델의 최종 RMSE 값 : {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 분류\n",
    "- 종속변수가 범주형인 데이터 예측 기법\n",
    "- 성능이 비슷한 모델을 결합해 더 나은 성능 향상 도출에 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Form\n",
    "- 실제론 cv모델을 많이 사용함.\n",
    "- basic form은 이해 위해 다룸!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 책에서 cancer 데이터로\n",
    "### 똑같이 진행해보겠음\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "cancer_data = load_breast_cancer\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델 생성\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "gbm_clf = GradientBoostingClassifier()\n",
    "# n_estimators는 생성할 의사결정 나무 갯수를 의미한다. 이 값이 100이면 100개의 의사결정 나무를 만들고 그 중 하나\n",
    "\n",
    "# 스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
    "lr_final = LogisticRegression(c=10)\n",
    "\n",
    "# 개별 모델 학습 시키기\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "gbm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 세트를 생성하고 개별 모델의 정확도 측정\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = knn_clf.predict(X_test)\n",
    "dt_pred = knn_clf.predict(X_test)\n",
    "ada_pred = knn_clf.predict(X_test)\n",
    "gbm_pred = gbm_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도 : {}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤포레스트 정확도 : {}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('의사결정 나무 정확도 : {}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도 : {}'.format(accuracy_score(y_test, ada_pred)))\n",
    "print('그라디언트부스트 정확도 : {}'.format(accuracy_score(y_test, gbm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred, gbm_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 칼럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final.fit(pred, y_test)\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도 : {}'.format(accuracy_score(y_test, final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    # 추후에 메타 모델이 사용할 학습 데이터 변환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros(X_test_n.shape[0], n_folds)\n",
    "    print(model.__class__.__name__, 'Model 시작')\n",
    "\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n",
    "        print('\\t 폴드세트 : ', folder_counter, '시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "\n",
    "        # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        # 입력된 원본 테스트 데이터를 폴드 세트 내 학습된 기반 모델에서 예측 후 데이터 저장\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "\n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "\n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)\n",
    "gbm_train, gbm_test = get_stacking_base_datasets(gbm_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train, gbm_train))\n",
    "stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test, gbm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final.fit(stack_final_X_train, y_train)\n",
    "stack_final = lr_final.fit(stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도 : {}'.format(accuracy_score(y_test, stack_final)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "476a94dc85aeef50ce38d52ab019ae32fa2a67ff1ac8045d45d38aa23f62cc9d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
