{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "- Hyper Parameter 최적의 조합 찾기\n",
    "- 코드를 짜서 일일이 하기 힘듬\n",
    "- 자동으로 반복을 돌며 파라미터를 측정해주는 함수\n",
    "- Hyper Parameter 많은 머신러닝 모델에선 반드시 사용, 유용\n",
    "- 교차검증은 시간이 많이 남을 때 하는 것! 시간, 비용 많이 들기 때문\n",
    "\n",
    "* esimator = classfier, regressor, pipline\n",
    "* param_grid = {key : [para1, para2, para3]}\n",
    "* scoring = 평가지표\n",
    "    - 정확도, 정밀도, 재현율\n",
    "* cv = 교차 검증을 위해 분할되는 학습/테스트셋의 갯수를 지정\n",
    "* refit = 디폴트 True, 최적의 하이퍼 파라미터를 찾은 뒤 재학습 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Exhaustive search over specified parameter values for an estimator.\n",
      "\n",
      "Important members are fit, predict.\n",
      "\n",
      "GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      "It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      "\"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      "implemented in the estimator used.\n",
      "\n",
      "The parameters of the estimator used to apply these methods are optimized\n",
      "by cross-validated grid-search over a parameter grid.\n",
      "\n",
      "Read more in the :ref:`User Guide <grid_search>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator object\n",
      "    This is assumed to implement the scikit-learn estimator interface.\n",
      "    Either estimator needs to provide a ``score`` function,\n",
      "    or ``scoring`` must be passed.\n",
      "\n",
      "param_grid : dict or list of dictionaries\n",
      "    Dictionary with parameters names (`str`) as keys and lists of\n",
      "    parameter settings to try as values, or a list of such\n",
      "    dictionaries, in which case the grids spanned by each dictionary\n",
      "    in the list are explored. This enables searching over any sequence\n",
      "    of parameter settings.\n",
      "\n",
      "scoring : str, callable, list, tuple or dict, default=None\n",
      "    Strategy to evaluate the performance of the cross-validated model on\n",
      "    the test set.\n",
      "\n",
      "    If `scoring` represents a single score, one can use:\n",
      "\n",
      "    - a single string (see :ref:`scoring_parameter`);\n",
      "    - a callable (see :ref:`scoring`) that returns a single value.\n",
      "\n",
      "    If `scoring` represents multiple scores, one can use:\n",
      "\n",
      "    - a list or tuple of unique strings;\n",
      "    - a callable returning a dictionary where the keys are the metric\n",
      "      names and the values are the metric scores;\n",
      "    - a dictionary with metric names as keys and callables a values.\n",
      "\n",
      "    See :ref:`multimetric_grid_search` for an example.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of jobs to run in parallel.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "\n",
      "    .. versionchanged:: v0.20\n",
      "       `n_jobs` default changed from 1 to None\n",
      "\n",
      "refit : bool, str, or callable, default=True\n",
      "    Refit an estimator using the best found parameters on the whole\n",
      "    dataset.\n",
      "\n",
      "    For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "    scorer that would be used to find the best parameters for refitting\n",
      "    the estimator at the end.\n",
      "\n",
      "    Where there are considerations other than maximum score in\n",
      "    choosing a best estimator, ``refit`` can be set to a function which\n",
      "    returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      "    case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "    according to the returned ``best_index_`` while the ``best_score_``\n",
      "    attribute will not be available.\n",
      "\n",
      "    The refitted estimator is made available at the ``best_estimator_``\n",
      "    attribute and permits using ``predict`` directly on this\n",
      "    ``GridSearchCV`` instance.\n",
      "\n",
      "    Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "    ``best_score_`` and ``best_params_`` will only be available if\n",
      "    ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "    scorer.\n",
      "\n",
      "    See ``scoring`` parameter to know more about multiple metric\n",
      "    evaluation.\n",
      "\n",
      "    .. versionchanged:: 0.20\n",
      "        Support for callable added.\n",
      "\n",
      "cv : int, cross-validation generator or an iterable, default=None\n",
      "    Determines the cross-validation splitting strategy.\n",
      "    Possible inputs for cv are:\n",
      "\n",
      "    - None, to use the default 5-fold cross validation,\n",
      "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "    - :term:`CV splitter`,\n",
      "    - An iterable yielding (train, test) splits as arrays of indices.\n",
      "\n",
      "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "    other cases, :class:`KFold` is used. These splitters are instantiated\n",
      "    with `shuffle=False` so the splits will be the same across calls.\n",
      "\n",
      "    Refer :ref:`User Guide <cross_validation>` for the various\n",
      "    cross-validation strategies that can be used here.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "\n",
      "verbose : int\n",
      "    Controls the verbosity: the higher, the more messages.\n",
      "\n",
      "    - >1 : the computation time for each fold and parameter candidate is\n",
      "      displayed;\n",
      "    - >2 : the score is also displayed;\n",
      "    - >3 : the fold and candidate parameter indexes are also displayed\n",
      "      together with the starting time of the computation.\n",
      "\n",
      "pre_dispatch : int, or str, default='2*n_jobs'\n",
      "    Controls the number of jobs that get dispatched during parallel\n",
      "    execution. Reducing this number can be useful to avoid an\n",
      "    explosion of memory consumption when more jobs get dispatched\n",
      "    than CPUs can process. This parameter can be:\n",
      "\n",
      "        - None, in which case all the jobs are immediately\n",
      "          created and spawned. Use this for lightweight and\n",
      "          fast-running jobs, to avoid delays due to on-demand\n",
      "          spawning of the jobs\n",
      "\n",
      "        - An int, giving the exact number of total jobs that are\n",
      "          spawned\n",
      "\n",
      "        - A str, giving an expression as a function of n_jobs,\n",
      "          as in '2*n_jobs'\n",
      "\n",
      "error_score : 'raise' or numeric, default=np.nan\n",
      "    Value to assign to the score if an error occurs in estimator fitting.\n",
      "    If set to 'raise', the error is raised. If a numeric value is given,\n",
      "    FitFailedWarning is raised. This parameter does not affect the refit\n",
      "    step, which will always raise the error.\n",
      "\n",
      "return_train_score : bool, default=False\n",
      "    If ``False``, the ``cv_results_`` attribute will not include training\n",
      "    scores.\n",
      "    Computing training scores is used to get insights on how different\n",
      "    parameter settings impact the overfitting/underfitting trade-off.\n",
      "    However computing the scores on the training set can be computationally\n",
      "    expensive and is not strictly required to select the parameters that\n",
      "    yield the best generalization performance.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "    .. versionchanged:: 0.21\n",
      "        Default value was changed from ``True`` to ``False``\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "cv_results_ : dict of numpy (masked) ndarrays\n",
      "    A dict with keys as column headers and values as columns, that can be\n",
      "    imported into a pandas ``DataFrame``.\n",
      "\n",
      "    For instance the below given table\n",
      "\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      "    +============+===========+============+=================+===+=========+\n",
      "    |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "\n",
      "    will be represented by a ``cv_results_`` dict of::\n",
      "\n",
      "        {\n",
      "        'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      "                                     mask = [False False False False]...)\n",
      "        'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      "                                    mask = [ True  True False False]...),\n",
      "        'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      "                                     mask = [False False  True  True]...),\n",
      "        'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      "        'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      "        'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      "        'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      "        'rank_test_score'    : [2, 4, 3, 1],\n",
      "        'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      "        'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      "        'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      "        'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      "        'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      "        'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      "        'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      "        'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      "        'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      "        }\n",
      "\n",
      "    NOTE\n",
      "\n",
      "    The key ``'params'`` is used to store a list of parameter\n",
      "    settings dicts for all the parameter candidates.\n",
      "\n",
      "    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "    ``std_score_time`` are all in seconds.\n",
      "\n",
      "    For multi-metric evaluation, the scores for all the scorers are\n",
      "    available in the ``cv_results_`` dict at the keys ending with that\n",
      "    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "    above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "\n",
      "best_estimator_ : estimator\n",
      "    Estimator that was chosen by the search, i.e. estimator\n",
      "    which gave highest score (or smallest loss if specified)\n",
      "    on the left out data. Not available if ``refit=False``.\n",
      "\n",
      "    See ``refit`` parameter for more information on allowed values.\n",
      "\n",
      "best_score_ : float\n",
      "    Mean cross-validated score of the best_estimator\n",
      "\n",
      "    For multi-metric evaluation, this is present only if ``refit`` is\n",
      "    specified.\n",
      "\n",
      "    This attribute is not available if ``refit`` is a function.\n",
      "\n",
      "best_params_ : dict\n",
      "    Parameter setting that gave the best results on the hold out data.\n",
      "\n",
      "    For multi-metric evaluation, this is present only if ``refit`` is\n",
      "    specified.\n",
      "\n",
      "best_index_ : int\n",
      "    The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "    candidate parameter setting.\n",
      "\n",
      "    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "    the parameter setting for the best model, that gives the highest\n",
      "    mean score (``search.best_score_``).\n",
      "\n",
      "    For multi-metric evaluation, this is present only if ``refit`` is\n",
      "    specified.\n",
      "\n",
      "scorer_ : function or a dict\n",
      "    Scorer function used on the held out data to choose the best\n",
      "    parameters for the model.\n",
      "\n",
      "    For multi-metric evaluation, this attribute holds the validated\n",
      "    ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "\n",
      "n_splits_ : int\n",
      "    The number of cross-validation splits (folds/iterations).\n",
      "\n",
      "refit_time_ : float\n",
      "    Seconds used for refitting the best model on the whole dataset.\n",
      "\n",
      "    This is present only if ``refit`` is not False.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "multimetric_ : bool\n",
      "    Whether or not the scorers compute several metrics.\n",
      "\n",
      "classes_ : ndarray of shape (n_classes,)\n",
      "    The classes labels. This is present only if ``refit`` is specified and\n",
      "    the underlying estimator is a classifier.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`. Only defined if\n",
      "    `best_estimator_` is defined (see the documentation for the `refit`\n",
      "    parameter for more details) and that `best_estimator_` exposes\n",
      "    `n_features_in_` when fit.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Only defined if\n",
      "    `best_estimator_` is defined (see the documentation for the `refit`\n",
      "    parameter for more details) and that `best_estimator_` exposes\n",
      "    `feature_names_in_` when fit.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The parameters selected are those that maximize the score of the left out\n",
      "data, unless an explicit score is passed in which case it is used instead.\n",
      "\n",
      "If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      "reasons if individual jobs take very little time, but may raise errors if\n",
      "the dataset is large and not enough memory is available.  A workaround in\n",
      "this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "n_jobs`.\n",
      "\n",
      "See Also\n",
      "---------\n",
      "ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      "train_test_split : Utility function to split the data into a development\n",
      "    set usable for fitting a GridSearchCV instance and an evaluation set\n",
      "    for its final evaluation.\n",
      "sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      "    loss function.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn import svm, datasets\n",
      ">>> from sklearn.model_selection import GridSearchCV\n",
      ">>> iris = datasets.load_iris()\n",
      ">>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      ">>> svc = svm.SVC()\n",
      ">>> clf = GridSearchCV(svc, parameters)\n",
      ">>> clf.fit(iris.data, iris.target)\n",
      "GridSearchCV(estimator=SVC(),\n",
      "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      ">>> sorted(clf.cv_results_.keys())\n",
      "['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " 'param_C', 'param_kernel', 'params',...\n",
      " 'rank_test_score', 'split0_test_score',...\n",
      " 'split2_test_score', ...\n",
      " 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/envs/datastudy/lib/python3.9/site-packages/sklearn/model_selection/_search.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "?GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4) (120,) (30,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                params  mean_test_score  rank_test_score  split0_test_score  \\\n",
       "0   {'n_neighbors': 1}         0.966667                5               0.95   \n",
       "1   {'n_neighbors': 3}         0.966667                5               0.95   \n",
       "2   {'n_neighbors': 5}         0.975000                1               0.95   \n",
       "3   {'n_neighbors': 7}         0.975000                1               0.95   \n",
       "4   {'n_neighbors': 9}         0.966667                5               0.95   \n",
       "5  {'n_neighbors': 11}         0.975000                1               0.95   \n",
       "6  {'n_neighbors': 13}         0.975000                1               0.95   \n",
       "\n",
       "   split1_test_score  split2_test_score  \n",
       "0              1.000              0.950  \n",
       "1              1.000              0.950  \n",
       "2              1.000              0.975  \n",
       "3              1.000              0.975  \n",
       "4              0.975              0.975  \n",
       "5              1.000              0.975  \n",
       "6              1.000              0.975  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=121, test_size=.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#지금까지의 방식 :\n",
    "#knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 훈련, 최적의 파라미터 찾기, 다시 훈련시키기까지 종합선물셋트 \n",
    "params = {'n_neighbors':[n for n in range(1, 15) if n%2 != 0]} # -> 1, 3, 5, 7, 9, 11, 13\n",
    "grid_knn = GridSearchCV(knn, param_grid=params,cv=3)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# 결과 확인\n",
    "grid_knn.cv_results_\n",
    "\n",
    "# 보기 어려우니 DataFrame으로 꾸며준다.\n",
    "\n",
    "scores_df = pd.DataFrame(grid_knn.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 : {'n_neighbors': 5}\n",
      "최고 정확도 : 0.975\n"
     ]
    }
   ],
   "source": [
    "print(\"최적의 파라미터 : {}\".format(grid_knn.best_params_))\n",
    "print(\"최고 정확도 : {}\".format(grid_knn.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도 : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#### 훈련 끝! 이제 테스트해야해\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "pred = grid_knn.predict(X_test)\n",
    "print(\"테스트 정확도 : {}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_refit_for_multimetric',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_select_best_index',\n",
       " '_validate_data',\n",
       " 'classes_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'n_features_in_',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_params',\n",
       " 'transform']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir(GridSearchCV)\n",
    "\n",
    "# ['__abstractmethods__',\n",
    "#  '__class__',\n",
    "#  '__delattr__',\n",
    "#  '__dict__',\n",
    "#  '__dir__',\n",
    "#  '__doc__',\n",
    "#  '__eq__',\n",
    "#  '__format__',\n",
    "#  '__ge__',\n",
    "#  '__getattribute__',\n",
    "#  '__getstate__',\n",
    "#  '__gt__',\n",
    "#  '__hash__',\n",
    "#  '__init__',\n",
    "#  '__init_subclass__',\n",
    "#  '__le__',\n",
    "#  '__lt__',\n",
    "#  '__module__',\n",
    "#  '__ne__',\n",
    "#  '__new__',\n",
    "#  '__reduce__',\n",
    "#  '__reduce_ex__',\n",
    "#  '__repr__',\n",
    "#  '__setattr__',\n",
    "#  '__setstate__',\n",
    "#  '__sizeof__',\n",
    "#  '__str__',\n",
    "#  '__subclasshook__',\n",
    "#  '__weakref__',\n",
    "#  '_abc_impl',\n",
    "#  '_check_feature_names',\n",
    "#  '_check_n_features',\n",
    "#  '_check_refit_for_multimetric',\n",
    "#  '_estimator_type',\n",
    "#  '_format_results',\n",
    "#  '_get_param_names',\n",
    "#  '_get_tags',\n",
    "#  '_more_tags',\n",
    "#  '_pairwise',\n",
    "#  '_repr_html_',\n",
    "#  '_repr_html_inner',\n",
    "#  '_repr_mimebundle_',\n",
    "#  '_required_parameters',\n",
    "#  '_run_search',\n",
    "#  '_select_best_index',\n",
    "#  '_validate_data',\n",
    "#  'classes_',\n",
    "#  'decision_function',\n",
    "#  'fit',\n",
    "#  'get_params',\n",
    "#  'inverse_transform',\n",
    "#  'n_features_in_',\n",
    "#  'predict',\n",
    "#  'predict_log_proba',\n",
    "#  'predict_proba',\n",
    "#  'score',\n",
    "#  'score_samples',\n",
    "#  'set_params',\n",
    "#  'transform']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
